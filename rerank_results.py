import json
import torch
from sentence_transformers import CrossEncoder
from tqdm import tqdm
import os
from config import Config

# Configuration
# Configuration
INPUT_RESULTS = "./PAR/results/test_results_3.json"
OUTPUT_RESULTS = "./PAR/results/test_results_3_reranked.json"
# Model PubMedBERT g·ªëc (C·∫ßn train th√™m m·ªõi hi·ªáu qu·∫£, n·∫øu d√πng ngay s·∫Ω nh∆∞ random)
CROSS_ENCODER_MODEL = "./output/cross-encoder-pubmedbert" 
TOP_K_RERANK = 50 # Gi·∫£m xu·ªëng 50 ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô (Latency)
SCORE_THRESHOLD = 0.5 # Ng∆∞·ª°ng ƒëi·ªÉm ƒë·ªÉ l·ªçc k·∫øt qu·∫£ kh√¥ng li√™n quan (Accuracy)

def load_data():
    """Load queries, corpus, and existing results."""
    print("Loading queries...")
    queries = {}
    with open(Config.TEST_QUERIES, 'r', encoding='utf-8') as f:
        for line in f:
            q = json.loads(line)
            queries[q['_id']] = q['text']

    print("Loading corpus (this might take a while)...")
    corpus = {}
    # L∆∞u √Ω: Load h·∫øt corpus v√†o RAM c√≥ th·ªÉ n·∫∑ng. 
    # N·∫øu RAM y·∫øu, n√™n d√πng c∆° ch·∫ø lazy load ho·∫∑c ch·ªâ load docs c√≥ trong results.
    # ·ªû ƒë√¢y m√¨nh demo c√°ch t·ªëi ∆∞u: Ch·ªâ load docs c·∫ßn thi·∫øt.
    
    # 1. ƒê·ªçc results tr∆∞·ªõc ƒë·ªÉ bi·∫øt c·∫ßn doc n√†o
    print(f"Loading results from {INPUT_RESULTS}...")
    with open(INPUT_RESULTS, 'r', encoding='utf-8') as f:
        results = json.load(f)
        
    needed_doc_ids = set()
    for qid, doc_scores in results.items():
        # L·∫•y top K doc ids c·ªßa m·ªói query
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:TOP_K_RERANK]
        for doc_id, _ in sorted_docs:
            needed_doc_ids.add(doc_id)
            
    print(f"Need to load {len(needed_doc_ids)} unique documents for reranking.")
    
    # 2. Scan corpus v√† ch·ªâ l·∫•y docs c·∫ßn
    with open(Config.CORPUS_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            doc = json.loads(line)
            doc_id = str(doc['_id'])
            if doc_id in needed_doc_ids:
                corpus[doc_id] = f"{doc.get('title', '')} {doc.get('text', '')}".strip()
                
    return queries, corpus, results

def rerank():
    queries, corpus, results = load_data()
    
    print(f"Loading Cross-Encoder: {CROSS_ENCODER_MODEL}...")
    # num_labels=1 ƒë·ªÉ output ra 1 ƒëi·ªÉm s·ªë (regression/ranking) thay v√¨ classification
    model = CrossEncoder(CROSS_ENCODER_MODEL, num_labels=1, max_length=512, device='cuda' if torch.cuda.is_available() else 'cpu')
    
    if torch.cuda.device_count() > 1:
        print(f"üöÄ Using {torch.cuda.device_count()} GPUs for Reranking!")
        model.model = torch.nn.DataParallel(model.model)
    
    reranked_results = {}
    
    print(f"Reranking top {TOP_K_RERANK} for {len(results)} queries...")
    for qid, doc_scores in tqdm(results.items()):
        if qid not in queries: continue
        
        query_text = queries[qid]
        
        # L·∫•y top K candidates t·ª´ k·∫øt qu·∫£ retrieval c≈©
        sorted_candidates = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:TOP_K_RERANK]
        
        # Chu·∫©n b·ªã pairs ƒë·ªÉ ƒë∆∞a v√†o Cross-Encoder: (Query, Doc)
        pairs = []
        valid_doc_ids = []
        
        for doc_id, initial_score in sorted_candidates:
            if doc_id in corpus:
                pairs.append([query_text, corpus[doc_id]])
                valid_doc_ids.append(doc_id)
        
        if not pairs:
            reranked_results[qid] = doc_scores # Gi·ªØ nguy√™n n·∫øu kh√¥ng c√≥ g√¨ ƒë·ªÉ rerank
            continue
            
        # Predict scores
        cross_scores = model.predict(pairs)
        
        # C·∫≠p nh·∫≠t l·∫°i ƒëi·ªÉm s·ªë
        new_scores = {}
        # Gi·ªØ l·∫°i c√°c docs n·∫±m ngo√†i top K (kh√¥ng ƒë∆∞·ª£c rerank) v·ªõi ƒëi·ªÉm c≈© (ho·∫∑c b·ªè qua t√πy chi·∫øn l∆∞·ª£c)
        # Chi·∫øn l∆∞·ª£c an to√†n: Copy to√†n b·ªô ƒëi·ªÉm c≈©, sau ƒë√≥ ghi ƒë√® top K b·∫±ng ƒëi·ªÉm m·ªõi
        # Tuy nhi√™n ƒëi·ªÉm Cross-Encoder (logits) kh√°c thang ƒëo v·ªõi Dot Product/L2.
        # N√™n t·ªët nh·∫•t l√† t√°ch bi·ªát: Top K reranked ƒë·ª©ng ƒë·∫ßu, c√≤n l·∫°i x·∫øp sau.
        
        # ·ªû ƒë√¢y m√¨nh s·∫Ω t·∫°o dict k·∫øt qu·∫£ m·ªõi ch·ªâ ch·ª©a Top K ƒë√£ rerank (ƒë·ªÉ evaluate MRR/NDCG@10)
        # N·∫øu mu·ªën gi·ªØ Recall@1000, c·∫ßn merge kh√©o l√©o h∆°n.
        
        filtered_scores = []
        for doc_id, score in zip(valid_doc_ids, cross_scores):
            # Ch·ªâ gi·ªØ l·∫°i c√°c b√†i c√≥ ƒëi·ªÉm cao h∆°n ng∆∞·ª°ng (n·∫øu c·∫ßn thi·∫øt)
            # Ho·∫∑c gi·ªØ t·∫•t c·∫£ nh∆∞ng s·∫Øp x·∫øp l·∫°i
            filtered_scores.append((doc_id, float(score)))
            
        # S·∫Øp x·∫øp l·∫°i theo ƒëi·ªÉm Cross-Encoder gi·∫£m d·∫ßn
        filtered_scores.sort(key=lambda x: x[1], reverse=True)
        
        # L·ªçc theo threshold (Optional: N·∫øu b·∫°n mu·ªën lo·∫°i b·ªè h·∫≥n c√°c b√†i k√©m)
        final_scores = {}
        for doc_id, score in filtered_scores:
            if score >= SCORE_THRESHOLD:
                final_scores[doc_id] = score
        
        # N·∫øu kh√¥ng c√≤n b√†i n√†o ƒë·∫°t ng∆∞·ª°ng, c√≥ th·ªÉ fallback l·∫•y b√†i cao ƒëi·ªÉm nh·∫•t ho·∫∑c tr·∫£ v·ªÅ r·ªóng
        if not final_scores and filtered_scores:
             # Fallback: L·∫•y b√†i t·ªët nh·∫•t d√π ƒëi·ªÉm th·∫•p, ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ b√°o "Kh√¥ng t√¨m th·∫•y"
             # ·ªû ƒë√¢y m√¨nh demo l·∫•y top 1 n·∫øu r·ªóng ƒë·ªÉ tr√°nh l·ªói pipeline, nh∆∞ng log warning
             # final_scores[filtered_scores[0][0]] = filtered_scores[0][1]
             pass

        reranked_results[qid] = final_scores

    # Save
    print(f"Saving reranked results to {OUTPUT_RESULTS}...")
    with open(OUTPUT_RESULTS, 'w', encoding='utf-8') as f:
        json.dump(reranked_results, f, indent=2)
        
    print("Done! Run evaluation on the new file.")

if __name__ == "__main__":
    rerank()
